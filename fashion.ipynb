{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = keras.datasets.fashion_mnist\n",
    "#deve-se perceber que os dados de fashion já estão resizados para 28x28\n",
    "(train_images,train_labels),(test_images,test_labels) = fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Camiseta','Calça','Suéter','Vestido','Casaco','Sandália','Camisa','Tênis','Bolsa','Bota'] #cria nome para cada label do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape) #mostra a quantidade de itens, e o formato\n",
    "print(train_labels) #mostra os labels\n",
    "print(len(train_labels)) #mostra a quantidade de labels de treino\n",
    "print(len(test_labels))  #mostra a quantidade de labels de teste\n",
    "#dessa forma 6k para teste, 1k para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#matplotlib é bugado com virtualenviroments, pode-se omitir isso em outros notebooks.\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "#deve-se perceber que os valores dos pixels vao de 0 até 255, ou seja, 256 possíveis valores, que sao todos os tons de RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0 #pq tem que ser 255???\n",
    "test_images = test_images/255.0 #de qual maneira isso é uma escalação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10)) #cria uma nova figura.\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1) #(linha, coluna) cria um novo eixo dentro da figura\n",
    "    plt.xticks([]) #sem parametros oculta os ticks de x e y crescentes\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i],cmap = plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo de rede neural sequencial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(128, activation = 'relu')) #camada densa de 128 neurônios.\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Na linha 2**, com o método **Flatten**, transformamos um array que tinha como elementos imagens bidimensionais (28x28) num array unidimensional de 784 pixels.\n",
    "Dessa forma, cada elemento do array unidimensional será uma lista de valores de cada um dos 784 pixels de uma única imagem.\n",
    "\n",
    "\n",
    "**Na linha 3**, com o método **Dense**, criamos uma camada neural que usa uma função de *retificação de unidade linear* para ativação. Se o valor for negativo ela retorna zero, e se for positivo ela retorna o próprio número. É uma boa função para redes neurais com um grande número de camadas pois ela consegue resolver o problema do gradiente que ocorre com a tanh e com a sigmóide.\n",
    "\n",
    "\n",
    "**Na linha 4**, com o método **Dense**, criamos uma camada neural cuja função de ativação é a *softmax*. Ela retorna um array de dez probabilidade. A soma de todas as probabilidades resulta em um. Cada nó contém um valor que indica a probabilidade de que aquela imagem pertence a uma das dez classes disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Então, para resumir:\n",
    "Alimentamos a rede neural com um array bidimensional que é transformado em unidimensional e depois passa por duas funções que no fim dizem em cada nó qual a probabilidade desta imagem ser a daquela classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um pouco mais sobre funções de ativação:\n",
    "A maneira mais fácil de treinar uma rede neural é com uma função linear, mas ela é incapaz de suportar estruturas complexas de dados. Dessa forma, as funções de ativação não lineares são preferidas pois são capaz de suportar tais estruturas. Usam-se as funções tangente hiperbólica e sigmóide pois não são lineares e transmitem o poder do gradiente por toda rede. \n",
    "\n",
    "Primeiro usou-se a função sigmóide, depois a hiperbólica pois esta performa melhor, porém, elas sofrem com saturação nas extremidades: somente no meio acontece algum tipo de mudança. Tal condição é a precursora de um erro que se propaga e infecta o resultado final.\n",
    "\n",
    "Então, para treinar uma rede de *aprendizado profundo* uma função que age como linear mas não é linear faz-se necessária. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agora, vamos treinar o modelo de rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porém, antes uma explicação:\n",
    "Antes de treinarmos a rede, precisamos compilar. E existem alguns parâmetros que são importantes para que consigamos a melhor performance. São as opções de otimização, de perda e de métricas.\n",
    "\n",
    "1. Otimização: é uma função que define qual algoritmo vai ser usado para ajustar os pesos usados nas camadas.\n",
    "2. Perda: é uma função escolhida que calcula quanto é o erro de predição da rede neural, quanto menor for o resultado dela, melhor.\n",
    "3. Métricas: usamos ela para medir a acurácia e ver qual fração das imagens que foi classificada corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images,train_labels, epochs=10) #input, targets, repetitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 2) A\n",
    "print(f'Test accuracy: {test_acc*100:.4}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudo sobre predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "a = np.argmax(predictions)\n",
    "print(predictions[a]) #imagem que teve maior taxa de acerto (?)\n",
    "print(np.argmax(predictions[a]))\n",
    "best_label = np.argmax(predictions[a])\n",
    "\n",
    "print(f'Nosso modelo acha que a imagem {a} é: {class_names[best_label]}')\n",
    "print(f'A classificação real da imagem é: {class_names[test_labels[a]]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotagem de um gráfico para visualização de predição de entre 10 classes.\n",
    "Veremos como o modelo se comportará dada uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array,true_label,img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img, cmap = plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array) #retiramos a label com maior porcentagem de acerto\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                  100*np.max(predictions_array),\n",
    "                                  class_names[true_label],\n",
    "                                  color = color))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i],true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10),class_names,rotation = 90)\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array,color='#777979')\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = a\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i,predictions,test_labels,test_images)\n",
    "#até aqui vemos a imagem analisada e sua porcentagem de acerto  e o valor real\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i,predictions,test_labels)\n",
    "#plt.xlabel()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=((2*2*num_cols),2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows,2*num_cols,2*i+1)\n",
    "    plot_image(i,predictions,test_labels,test_images)\n",
    "    plt.subplot(num_rows,2*num_cols,2*i+2)\n",
    "    plot_value_array(i,predictions,test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIM\n",
    "Com isso, terminamos nosso hello_world.fit() :)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "345234270d4874a93a6ab45b033768b447099900a5790e5f3afec9be8c725683"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}